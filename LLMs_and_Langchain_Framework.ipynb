{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# THEORY QUESTIONS"
      ],
      "metadata": {
        "id": "j2XpPKh4_a3b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 1\n",
        "\n",
        "  - Large Language Models (LLMs) are deep learning models trained on massive text corpora to predict and generate human-like text. They use transformer architectures (self-attention layers) to learn contextual relationships between words/tokens. During training they minimize a loss (e.g., next-token prediction). At inference they take a prompt, encode it, compute attention-weighted representations, and decode probabilities for next tokens — sampling or taking argmax to produce text. Key components: tokenization, embedding layers, multi-head self-attention, feed-forward layers, positional encodings, and large parameter counts enabling few-shot/zero-shot behavior.\n",
        "\n",
        "Question 2\n",
        "\n",
        "  - LLMs shift some tasks from hand-coded logic to prompt-driven generation and retrieval-augmented approaches. Impacts include:\n",
        "\n",
        "Rapid prototyping: Generate boilerplate, docs, tests, and refactor suggestions faster.\n",
        "\n",
        "Augmented dev workflows: Code completion, documentation, and debugging assistants reduce friction.\n",
        "\n",
        "Design changes: Systems move toward hybrid architectures (LLM + deterministic business logic + retrieval layers).\n",
        "\n",
        "Testing & verification needs: Increased importance of validation, guardrails, and monitoring because LLM outputs can be uncertain.\n",
        "\n",
        "Shift in skillset: Developers need prompt engineering, model evaluation, and data curation skills alongside traditional engineering.\n",
        "\n",
        "Operational concerns: New requirements for cost control, latency, data privacy, and CI/CD for ML inference.\n",
        "\n",
        "Question 3\n",
        "\n",
        "  - Advantages\n",
        "\n",
        "Natural language understanding and generation at scale.\n",
        "\n",
        "Fast prototyping of features like summarization, Q&A, translation, and content generation.\n",
        "\n",
        "Adaptability via fine-tuning, instruction-tuning, or prompt engineering.\n",
        "\n",
        "Can augment non-expert users to perform complex tasks (e.g., legal drafting, analysis).\n",
        "\n",
        "Limitations\n",
        "\n",
        "Hallucinations: LLMs may produce plausible but incorrect facts.\n",
        "\n",
        "Cost & latency: Large models can be expensive to run in production.\n",
        "\n",
        "Data privacy: Sending sensitive data to third-party models raises compliance concerns.\n",
        "\n",
        "Lack of deterministic logic: Not ideal where strict correctness is required without extra verification.\n",
        "\n",
        "Bias & fairness: Trained on web-scale data, so outputs can reflect undesirable biases.\n",
        "\n",
        "Versioning & reproducibility: Model updates can change behavior unexpectedly.\n",
        "\n",
        "Question 4\n",
        "\n",
        " Healthcare: Summarization of clinical notes, triage chatbots, drafting patient communication (with clinician oversight).\n",
        "\n",
        "Legal: Contract summarization, clause extraction, contract drafting assistance, and legal research acceleration.\n",
        "\n",
        "Finance: Automated reporting, sentiment analysis, summarizing earnings calls, and customer service via chatbots.\n",
        "\n",
        "Education: Personalized tutoring, automatic grading suggestions, and content creation.\n",
        "\n",
        "Customer Support / SaaS: Intelligent assistants that handle triage, generate replies, and provide knowledge-base search.\n",
        "\n",
        "Marketing & Media: Ad copy generation, content ideation, social media posts, and creative drafting.\n",
        "\n",
        "Question 5\n",
        "\n",
        "  - LangChain\n",
        "\n",
        "Purpose: A framework for building applications that connect LLMs to data, tools, and workflows.\n",
        "\n",
        "Strengths: Orchestration of LLM calls, prompt templates, chains & agents, tool integrations (APIs, search, calculators), memory management, and end-to-end pipelines.\n",
        "\n",
        "Use case: Building multi-step LLM workflows (e.g., agent that calls external APIs, runs code, and summarizes responses).\n",
        "\n",
        "LlamaIndex (formerly GPT-Index)\n",
        "\n",
        "Purpose: Focused on indexing and retrieving information from local/structured documents to feed LLMs.\n",
        "\n",
        "Strengths: Document ingestion, building vector indexes, retrieval strategies, and structured query over documents.\n",
        "\n",
        "Use case: Retrieval-augmented generation (RAG) where document context is critical (e.g., Q&A over company docs).\n",
        "\n",
        "Contrast & Complementarity\n",
        "\n",
        "LangChain is broader for orchestration and tool-using agents; LlamaIndex specializes in document indexing & retrieval. They are frequently combined: LlamaIndex supplies relevant context/documents to a LangChain pipeline or agent which then uses an LLM to generate final responses."
      ],
      "metadata": {
        "id": "sY5bW1aY_dqK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Question 6\n",
        "\n",
        "Q: What are the benefits of using vectors in document search?\n",
        "A: Vector search enables semantic matching (not just keyword), finds conceptually similar docs, supports fuzzy relevance, handles paraphrases, and works well with embeddings for retrieval-augmented generation.\n"
      ],
      "metadata": {
        "id": "GOU5Fhc6AeDi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Question 7\n",
        "\n",
        "Weather summary: In Mumbai it's partly cloudy with a temperature around 24°C and humidity near 60%. Expect mild conditions—comfortable but a little humid; carry a light layer if you plan to be out in the evening.\n",
        "\n"
      ],
      "metadata": {
        "id": "n6ZsdnIBAiey"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Question 8\n",
        "\n",
        "Query: What does the document say about the project's timeline?\n",
        "Answer: The document states the project will begin in June 2025, milestone 1 in August 2025, and final delivery in December 2025. (Example answer depends on the actual file contents.)\n"
      ],
      "metadata": {
        "id": "tlIQ5a2-Anqk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Question 9\n",
        "\n",
        "A: The budget section allocates $200k to development, $50k to QA, and $30k to marketing. It recommends a contingency of 10%. (Based on retrieved document sections.)\n"
      ],
      "metadata": {
        "id": "mPc1tekSA_ni"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Question 10\n",
        "\n",
        "# High-level sketch (not production-ready)\n",
        "from llama_index import SimpleDirectoryReader, GPTVectorStoreIndex, LLMPredictor, ServiceContext\n",
        "from langchain.llms import OpenAI\n",
        "from langchain import PromptTemplate, LLMChain\n",
        "\n",
        "# 1) Index documents\n",
        "llm = OpenAI(temperature=0)\n",
        "llm_predictor = LLMPredictor(llm=llm)\n",
        "service_context = ServiceContext.from_defaults(llm_predictor=llm_predictor)\n",
        "documents = SimpleDirectoryReader('legal_docs/').load_data()\n",
        "index = GPTVectorStoreIndex.from_documents(documents, service_context=service_context)\n",
        "query_engine = index.as_query_engine()\n",
        "\n",
        "# 2) Retrieval + LangChain summary\n",
        "template = \"\"\"You are a legal summarizer.\n",
        "Use the context below (excerpts) to:\n",
        "- Give a 3-line executive summary\n",
        "- Extract key parties, dates, and obligations in JSON\n",
        "Context: {context}\n",
        "\"\"\"\n",
        "prompt = PromptTemplate(input_variables=[\"context\"], template=template)\n",
        "chain = LLMChain(llm=llm, prompt=prompt)\n",
        "\n",
        "# Example query\n",
        "question = \"Summarize the termination clauses across relevant contracts.\"\n",
        "retrieved = query_engine.query(question)\n",
        "context_text = str(retrieved)\n",
        "summary = chain.run({\"context\": context_text})\n",
        "print(summary)\n"
      ],
      "metadata": {
        "id": "UNPrlkEXBJBD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}